#%% [markdown]
# ## TWICE íŠ¸ìœ— ğŸ¤–
# ### íŠ¸ì™€ì´ìŠ¤ì˜ íŠ¸ìœ—ì„ ëª¨ì•„ì£¼ëŠ” ë´‡ì…ë‹ˆë‹¤.
#
# ### ì°¸ê³  ì‚¬ì´íŠ¸
#  
# - [ê°œë°œ í™˜ê²½ ë§Œë“¤ê¸°](https://github.com/moabogey/docs/wiki/ê°œë°œí™˜ê²½ë§Œë“¤ê¸°)
#
# - [ì˜ˆì œ ì½”ë“œ ì‹¤í–‰](https://github.com/moabogey/docs/wiki/ì˜ˆì œì½”ë“œì‹¤í–‰)
#
# - [ì½”ë”©ì„ í•˜ê¸° ì „ì—](https://github.com/moabogey/docs/wiki/ì½”ë”©í•˜ê¸°ì „ì—)
#
# - [ì˜ˆì œ ì½”ë“œ ë¶„ì„](https://github.com/moabogey/docs/wiki/ì˜ˆì œì½”ë“œë¶„ì„)
#
# - [ë´‡ ê°œë°œ í•˜ê¸°](https://github.com/moabogey/docs/wiki/ë´‡ê°œë°œí•˜ê¸°)

#%%
import requests
from requests.exceptions import HTTPError
from bs4 import BeautifulSoup
import re
import json
from datetime import datetime
from datetime import timedelta

if __debug__:
    import os.path

# ëª¨ì•„ë³´ê¸° ì»´í¬ë„ŒíŠ¸ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
import moabogey_database as moabogey
from moabogey_id import *

# ì‚¬ì´íŠ¸ ì´ë¦„
site_name = 'twitter'
# ì‚¬ì´íŠ¸ì—ì„œ ê°€ì ¸ì˜¬ ì£¼ì œ
subject_name = 'JYPETWICE'
# ì‚¬ì´íŠ¸ ì£¼ì†Œ
site_url = 'https://twitter.com/JYPETWICE'
if __debug__:
    print('{} ë°ì´í„° ìˆ˜ì§‘ ì¤‘... âš™ï¸'.format(site_url))

# ì‚¬ì´íŠ¸ì˜ HTMLì„ ê°€ì ¸ì˜¨ë‹¤.
try:
    response = requests.get(site_url)
    # ì—ëŸ¬ê°€ ë°œìƒ í–ˆì„ ê²½ìš° ì—ëŸ¬ ë‚´ìš©ì„ ì¶œë ¥í•˜ê³  ì¢…ë£Œí•œë‹¤.
    response.raise_for_status()
except HTTPError as http_err:
    print(f'HTTP error occurred: {http_err}')
except Exception as err:
    print(f'Other error occurred: {err}')
else:
    html_source = response.text
    
    # BeautifulSoup ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.
    soup = BeautifulSoup(html_source, 'html.parser')
    
    # HTMLì„ ë¶„ì„í•˜ê¸° ìœ„í•´ì„œ í˜ì´ì§€ì˜ ì†ŒìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.
    if __debug__:
        file_name = site_name + '_source.html'
        if not os.path.isfile(file_name):
            print('file save: ', file_name)
            with open(file_name, 'w', encoding='utf-8') as f:
                f.write(soup.prettify())

    # ë°ì´í„°ë¥¼ ì €ì¥í•  ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•œë‹¤. 
    # bot_idëŠ” moabogey_idì—ì„œ ê°€ì ¸ì˜¨ ê°’ì´ë‹¤.
    db_name = subject_name + '_on_' + site_name 
    my_db = moabogey.Dbase(db_name, bot_id)
            
    # ë°˜ë³µí•´ì„œ í¬ìŠ¤íŠ¸ì˜ ëª©ë¡ì„ í•˜ë‚˜ì”© ê²€ìƒ‰í•˜ë©° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œë‹¤.
    for post in soup.find_all('div', class_='content'):
        # í¬ìŠ¤íŠ¸ë¥¼ ì˜¬ë¦° ì‘ì„±ìë¥¼ ìˆ˜ì§‘í•œë‹¤.
        moa_createBy = post.find('strong', class_='fullname').text.strip()
        #print('createdBy: ', moa_createBy)

        # í¬ìŠ¤íŠ¸ì˜ ì£¼ì†Œë¥¼ ìˆ˜ì§‘í•œë‹¤.
        href = post.find('a', {"class": "tweet-timestamp", "href": True})
        if href:
            href = href['href'] 
            href_url = 'https://twitter.com' + href
            #print('href: ', href_url)

            # í¬ìŠ¤íŠ¸ë¥¼ ì˜¬ë¦° ë‚ ì§œë¥¼ ìˆ˜ì§‘í•œë‹¤.
            if __debug__:
                # LANGUAGE KOREA CASE
                post_time = post.find('a', class_="tweet-timestamp")['title'].replace('ì˜¤ì „', 'AM').replace('ì˜¤í›„', 'PM')
                # ì‹œê°„ í˜•ì‹ - AM 2:27 - 2019ë…„ 3ì›” 11ì¼
                moa_createdAt = datetime.strptime(post_time, '%p %I:%M - %Yë…„ %mì›” %dì¼')
            else:
                # LANGUAGE UNDEFINED CASE
                post_time = post.find('a', class_="tweet-timestamp")['title']
                # ì‹œê°„ í˜•ì‹ - 8:01 PM - 30 Mar 2019
                moa_createdAt = datetime.strptime(post_time, '%I:%M %p - %d %b %Y')

            # ì‹œê°„ì„ ë³´ì •í•œë‹¤. UTC (+7) ?
            moa_createdAt = moa_createdAt + timedelta(hours=7)

            # í¬ìŠ¤íŠ¸ì˜ HTMLì„ ê°€ì ¸ì˜¨ë‹¤.
            try:
                response =  requests.get(href_url)
                response.raise_for_status()
            except HTTPError as http_err:
                print(f'HTTP error occurred: {http_err}')
            except Exception as err:
                print(f'Other error occurred: {err}')
            else:
                subhtml_source = response.text
                # BeautifulSoup ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.
                post = BeautifulSoup(subhtml_source, 'html.parser')

                # HTMLì„ ë¶„ì„í•˜ê¸° ìœ„í•´ì„œ í¬ìŠ¤íŠ¸ì˜ ì†ŒìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.
                if __debug__:
                    file_name = site_name + '_post_source.html'
                    if not os.path.isfile(file_name):
                        print('file save: ', file_name)
                        with open(file_name, 'w', encoding='utf-8') as f:
                            f.write(post.prettify())

                # í¬ìŠ¤íŠ¸ ì œëª©ì„ ìˆ˜ì§‘/ê°€ê³µ í•œë‹¤.
                #moa_title = post.find('meta', property="og:title")
                moa_title = post.find('meta', property="og:description")
                if moa_title:
                    moa_title = moa_title['content'].splitlines()[0]
                
                # í¬ìŠ¤íŠ¸ ìš”ì•½ì„ ìˆ˜ì§‘/ê°€ê³µí•œë‹¤.
                moa_desc = post.find('meta', property="og:description")
                if moa_desc:
                    moa_desc = ''.join(moa_desc['content'].splitlines()[1:])
                
                # ëŒ€í‘œ ì´ë¯¸ì§€ì˜ ì£¼ì†Œë¥¼ ìˆ˜ì§‘í•œë‹¤.
                moa_image = post.find('meta', property="og:image")
                if moa_image:
                    moa_image = moa_image['content']
                
                # ì‚¬ì´íŠ¸ ì´ë¦„ì„ ìˆ˜ì§‘í•œë‹¤.
                moa_site_name = post.find('meta', property="og:site_name")
                if moa_site_name:
                    moa_site_name = moa_site_name['content']
                
                # í¬ìŠ¤íŠ¸ì˜ ì£¼ì†Œë¥¼ ê°€ê³µí•œë‹¤.
                moa_url = 'https://mobile.twitter.com' + href
                
                # í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ìˆ˜ì§‘í•œë‹¤.
                moa_timeStamp = datetime.now()

                # ì˜¤ëŠ˜ ë°œí–‰ëœ í¬ìŠ¤íŠ¸ë§Œ ì„ íƒí•œë‹¤.
                delta = moa_timeStamp - moa_createdAt + timedelta(hours=9)
                if delta.days <=0:
                
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” í¬ìŠ¤íŠ¸ì™€ ì¤‘ë³µë˜ëŠ”ì§€ë¥¼ í™•ì¸í•œë‹¤.
                    if my_db.isNewItem('title', moa_title):
                        # ë°ì´í„° íƒ€ì…ì„ í™•ì¸í•œë‹¤.
                        assert type(moa_title) == str, 'title: type error'
                        assert type(moa_desc) == str, 'desc: type error'
                        assert type(moa_url) == str, 'url: type error'
                        assert type(moa_image) == str, 'image: type error'
                        assert type(moa_site_name) == str, 'siteName: type error'
                        assert type(moa_createBy) == str, 'createBy: type error'
                        assert type(moa_createdAt) == datetime, 'createdAt: type error'
                        assert type(moa_timeStamp) == datetime, 'timeStamp: type error'
                        
                        # JSONí˜•ì‹ìœ¼ë¡œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë³€í™˜í•œë‹¤.
                        db_data = { 'title': moa_title, 
                            'desc': moa_desc,
                            'url': moa_url,
                            'image': moa_image,
                            'siteName': moa_site_name,
                            'createdBy': moa_createBy,
                            'createdAt': moa_createdAt,
                            'timeStamp': moa_timeStamp
                        }

                        if __debug__:
                            # ë””ë²„ê·¸ë¥¼ ìœ„í•´ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ì¶œë ¥í•œë‹¤.
                            temp_data = db_data.copy()
                            temp_data['desc'] = temp_data['desc'][:20] + '...'
                            print('ğŸ“€ ìˆ˜ì§‘í•œ json data: ')
                            print(json.dumps(temp_data, indent=4, ensure_ascii=False, default=str))

                        # ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì „ì†¡í•œë‹¤.
                        my_db.insertTable(db_data)

    # ë°ì´í„° ë² ì´ìŠ¤ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ë””ìŠ¤í”Œë ˆì´ í•œë‹¤.
    if __debug__:
        my_db.displayHTML()

    # ë°ì´í„° ë² ì´ìŠ¤ë¥¼ ë‹«ëŠ”ë‹¤.
    my_db.close()
    